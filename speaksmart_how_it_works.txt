SPEAKSMART INCOGNITO - HOW THE AI APP WORKS (TECHNICAL WORKFLOW)
===================================================================

1. FRONTEND: THE USER INTERFACE (index.html, style.css, script.js)
   * The user opens the SpeakSmart dashboard (http://localhost:8000) inside their web browser.
   * "Generate Topic" provides a random subject for the user to speak about.
   * When the user clicks "RECORD", the browser uses the native `navigator.mediaDevices.getUserMedia()` API to gain access to the microphone.
   * The `MediaRecorder` API captures the incoming audio snippets as the user speaks and saves them temporarily in the browser's memory as a WebM Blob.
   * A visual timer tracks the duration (`GameState.duration`).

2. FRONTEND: AUDIO ENCODING (script.js -> audioBufferToWav)
   * When the user clicks "STOP", the `MediaRecorder` finishes the recording.
   * Because Python's standard `SpeechRecognition` library cannot easily read WebM files without external C++ decoders (like FFmpeg) installed on Windows, the frontend performs a conversion.
   * The application uses the `window.AudioContext` API to decode the WebM Blob perfectly into raw pulse-code modulation (PCM) arrays.
   * A custom Javascript function (`audioBufferToWav`) rewrites these raw audio arrays into a strict, 16-bit, 44.1kHz `.wav` format.
   * This `.wav` file, along with the `topic` and `duration`, is packaged into a `FormData` object.
   * A Javascript `fetch()` POST request sends this package securely to the Python backend API at `http://localhost:5000/api/analyze`.

3. BACKEND: SPEECH-TO-TEXT (app.py)
   * The Flask server receives the POST request. It temporarily saves the valid `.wav` file as `temp_recording.wav`.
   * Python uses the `speech_recognition` library, which safely opens the `.wav` file using standard system audio readers.
   * It sends the audio payload to the free `recognize_google()` API, which converts the spoken audio into a written text transcript.
   * The backend measures the Word Count and mathematically determines the Words-Per-Minute (WPM) by dividing Word Count by the payload `duration`.
   * It also runs a native check counting specific "filler words" (um, uh, like) within the transcript.

4. BACKEND: GOOGLE GEMINI AI COACHING (app.py)
   * The backend dynamically generates a specialized prompt combining the `topic` and the generated `transcript`.
   * It asks Google to act as an Expert Public Speaking Coach.
   * Using the `google-generativeai` package and the secure `GEMINI_API_KEY` stored in `.env`, the server queries the `gemini-flash-latest` model.
   * Gemini evaluates the text and returns a strict JSON object containing:
      - A Confidence Score (0-100)
      - A Coaching Feedback paragraph praising strengths and criticizing weaknesses.
      - A list of two specific Improvements for the speaker.
   * The backend gathers the `transcript`, `wpm`, `fillers`, and the Gemini `analysis` JSON and returns it all to the frontend.
   * The temporary `.wav` file is then safely deleted from the server.

5. FRONTEND: GAMIFICATION & FEEDBACK (script.js)
   * The browser receives the JSON package from Python.
   * The Live Transcript area updates instantly with the user's spoken words.
   * The animated Data Cards count up to display the WPM, Fillers, and Gemini Confidence Score.
   * The neon "Coach Feedback" box becomes visible, displaying Gemini's exact paragraph and bullet-pointed improvements.
   * Game Logic kicks in: Experience Points (XP) are generated using a mathematical formula based on the `duration` of the speech + the `Confidence Score` + bonuses for zero filler words.
   * The user levels up, unlocking animated badges on the dashboard array!
